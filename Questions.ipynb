{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from classes.PostgresConnect import PostgresConnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres = PostgresConnect()\n",
    "postgres.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classes.PostgresConnect.PostgresConnect at 0x115a04c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postgres.sql(\"sql/questions/reset.sql\",file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les départements qui correspondent a la région aquitaine:\n",
      "\t- Charente\n",
      "\t- Charente-Maritime\n",
      "\t- Corrèze\n",
      "\t- Creuse\n",
      "\t- Deux-Sèvres\n",
      "\t- Dordogne\n",
      "\t- Gironde\n",
      "\t- Haute-Vienne\n",
      "\t- Landes\n",
      "\t- Lot-et-Garonne\n",
      "\t- Pyrénées-Atlantiques\n",
      "\t- Vienne\n"
     ]
    }
   ],
   "source": [
    "# requête interactive\n",
    "\n",
    "region = 'aquitaine' # mettre a jour le contenu ici pour changer de région (i.e: tagne -> Bretagne, compte -> Franche compté etc)\n",
    "\n",
    "# Ne plus modifier ci-dessous\n",
    "query = \"select d.libelle from departements d join regions r using(reg) where r.ncc LIKE UPPER(%(region)s) or r.libelle LIKE UPPER(%(region)s) order by d.libelle\"\n",
    "params = {'region': f'%{region}%'}\n",
    "\n",
    "data = postgres.sql(query=query, params=params).all()\n",
    "\n",
    "print(f'Les départements qui correspondent a la région {region}:')\n",
    "for dep in data:\n",
    "    print(f'\\t- {dep[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information pour l'indicateur pop pour la commune bordeaux (33 )\n",
      "\t1975: 223,131.0\n",
      "\t1968: 266,662.0\n",
      "\t1982: 208,159.0\n",
      "\t2008: 235,891.0\n",
      "\t1990: 210,336.0\n",
      "\t1999: 215,363.0\n",
      "\t2013: 243,626.0\n",
      "\t2018: 257,068.0\n"
     ]
    }
   ],
   "source": [
    "# requête interactive\n",
    "\n",
    "commune = 'bordeaux'  # le nom de la ville doit être exact, sans accent ni caractère spéciaux\n",
    "indicateur = 'pop'  # parmis DECE, LOG, LOGVAC, NAIS, NPER, PMEN, POP, RP, RSECOCC, SUPERF\n",
    "\n",
    "# Ne plus modifier ci-dessous\n",
    "data = postgres.sql(\n",
    "    query=\"select annee, ncc, dep,valeur from communes c join statistiques s on s.codgeo = c.com where upper(s.indicateur) = upper(%(indicateur)s) and c.ncc = upper( %(commune)s)\", \n",
    "    params={'commune': commune, 'indicateur': indicateur}\n",
    "    ).all()\n",
    "\n",
    "if(len(data)):\n",
    "    print(f\"Information pour l'indicateur {indicateur} pour la commune {commune} ({data[0][2]})\")\n",
    "    for info in data:\n",
    "        print(f'\\t{info[0]}: {info[3]:,}')\n",
    "else:\n",
    "    print(f'aucune information pour la commune de {commune} et l\\'indicateur {indicateur}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 villes les plus peuplées de France en 2018:\n",
      "\t- Paris: 2,175,601 habitants\n",
      "\t- Marseille: 868,277 habitants\n",
      "\t- Lyon: 518,635 habitants\n",
      "\t- Toulouse: 486,828 habitants\n",
      "\t- Nice: 341,032 habitants\n",
      "\t- Nantes: 314,138 habitants\n",
      "\t- Montpellier: 290,053 habitants\n",
      "\t- Strasbourg: 284,677 habitants\n",
      "\t- Bordeaux: 257,068 habitants\n",
      "\t- Lille: 233,098 habitants\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "data = postgres.sql(\"sql/questions/question_1/question_1#1.sql\",file=True).all()\n",
    "\n",
    "print('Les 10 villes les plus peuplées de France en 2018:')\n",
    "for ville in data:\n",
    "    print(f'\\t- {ville[0]}: {ville[1]:,} habitants')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évolution de la population Française au fil des années:\n",
      "\n",
      "\t- Année 1968: 50,798,112 habitants -> +0 habitants (0%)\n",
      "\t\t- Naissances: 6,149,732 | Décès: 3,909,870\n",
      "\n",
      "\t- Année 1975: 53,764,064 habitants -> +2,965,952 habitants (5.516606780320774%)\n",
      "\t\t- Naissances: 5,532,080 | Décès: 3,911,267\n",
      "\t\t- Augmentation: 2,965,952 || Naissances - Décès: 1,620,813 || Différence: 1,345,139\n",
      "\n",
      "\t- Année 1982: 55,569,542 habitants -> +1,805,478 habitants (3.2490424340729676%)\n",
      "\t\t- Naissances: 6,363,297 | Décès: 4,375,209\n",
      "\t\t- Augmentation: 1,805,478 || Naissances - Décès: 1,988,088 || Différence: -182,610\n",
      "\n",
      "\t- Année 1990: 58,040,659 habitants -> +2,471,117 habitants (4.257561927406786%)\n",
      "\t\t- Naissances: 6,877,418 | Décès: 4,819,081\n",
      "\t\t- Augmentation: 2,471,117 || Naissances - Décès: 2,058,337 || Différence: 412,780\n",
      "\n",
      "\t- Année 1999: 60,149,901 habitants -> +2,109,242 habitants (3.506642513010952%)\n",
      "\t\t- Naissances: 7,211,899 | Décès: 4,833,385\n",
      "\t\t- Augmentation: 2,109,242 || Naissances - Décès: 2,378,514 || Différence: -269,272\n",
      "\n",
      "\t- Année 2008: 63,961,859 habitants -> +3,811,958 habitants (5.959736098351988%)\n",
      "\t\t- Naissances: 4,122,043 | Décès: 2,747,875\n",
      "\t\t- Augmentation: 3,811,958 || Naissances - Décès: 1,374,168 || Différence: 2,437,790\n",
      "\n",
      "\t- Année 2013: 65,564,756 habitants -> +1,602,897 habitants (2.444754007778203%)\n",
      "\t\t- Naissances: 3,936,486 | Décès: 2,909,198\n",
      "\t\t- Augmentation: 1,602,897 || Naissances - Décès: 1,027,288 || Différence: 575,609\n",
      "\n",
      "\t- Année 2018: 66,732,538 habitants -> +1,167,782 habitants (1.7499439328982211%)\n",
      "\t\t- Naissances: 0 | Décès: 0\n",
      "\t\t- Augmentation: 1,167,782 || Naissances - Décès: 0 || Différence: 1,167,782\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "data = postgres.sql(\"sql/questions/question_1/question_1#2.sql\",file=True).all()\n",
    "\n",
    "print('Évolution de la population Française au fil des années:')\n",
    "for population in data:\n",
    "    population = [0 if v is None else v for v in population]\n",
    "    print(f'\\n\\t- Année {population[0]}: {population[1]:,} habitants -> +{population[2]:,} habitants ({population[3]}%)')\n",
    "    print(f'\\t\\t- Naissances: {population[4]:,} | Décès: {population[5]:,}')\n",
    "    if(population[2]):\n",
    "        print(f'\\t\\t- Augmentation: {population[2]:,} || Naissances - Décès: {population[4] - population[5]:,} || Différence: {population[2]-(population[4] - population[5]):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ville la plus peuplée de chaque région en 2018:\n",
      "\t- Région Île-de-France -> Paris (75056): 2,175,601 habitants\n",
      "\t- Région Provence-Alpes-Côte d'Azur -> Marseille (13055): 868,277 habitants\n",
      "\t- Région Auvergne-Rhône-Alpes -> Lyon (69123): 518,635 habitants\n",
      "\t- Région Occitanie -> Toulouse (31555): 486,828 habitants\n",
      "\t- Région Pays de la Loire -> Nantes (44109): 314,138 habitants\n",
      "\t- Région Grand Est -> Strasbourg (67482): 284,677 habitants\n",
      "\t- Région Nouvelle-Aquitaine -> Bordeaux (33063): 257,068 habitants\n",
      "\t- Région Hauts-de-France -> Lille (59350): 233,098 habitants\n",
      "\t- Région Bretagne -> Rennes (35238): 217,728 habitants\n",
      "\t- Région Normandie -> Le Havre (76351): 169,733 habitants\n",
      "\t- Région Bourgogne-Franche-Comté -> Dijon (21231): 156,854 habitants\n",
      "\t- Région La Réunion -> Saint-Denis (97411): 150,535 habitants\n",
      "\t- Région Centre-Val de Loire -> Tours (37261): 136,463 habitants\n",
      "\t- Région Martinique -> Fort-de-France (97209): 78,126 habitants\n",
      "\t- Région Corse -> Ajaccio (2A004): 70,817 habitants\n",
      "\t- Région Guyane -> Cayenne (97302): 63,652 habitants\n",
      "\t- Région Guadeloupe -> Les Abymes (97101): 53,082 habitants\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "data = postgres.sql(\"sql/questions/question_1/question_1#3.sql\",file=True).all()\n",
    "\n",
    "print('Ville la plus peuplée de chaque région en 2018:')\n",
    "for population in data:\n",
    "    print(f'\\t- Région {population[2]} -> {population[1]} ({population[0]}): {population[3]:,} habitants')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classes.PostgresConnect.PostgresConnect at 0x115a04c70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création des vues\n",
    "\n",
    "postgres.sql(\"sql/questions/question_2/question_2#vue_region.sql\",file=True).sql(\"sql/questions/question_2/question_2#vue_departements.sql\",file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUVERGNE RHONE ALPES: None\n",
      "BOURGOGNE FRANCHE COMTE: None\n",
      "BRETAGNE: None\n",
      "CENTRE VAL DE LOIRE: None\n",
      "CORSE: None\n"
     ]
    }
   ],
   "source": [
    "# Ajout des colonnes population\n",
    "data = postgres.sql(\"sql/questions/question_3/alter_tables.sql\",file=True).sql(\"select ncc,population from regions order by ncc limit 5;\").all()\n",
    "\n",
    "\n",
    "for region in data:\n",
    "    print(f'{region[0]}: {region[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUVERGNE RHONE ALPES: 7994459\n",
      "BOURGOGNE FRANCHE COMTE: 2807807\n",
      "BRETAGNE: 3335414\n",
      "CENTRE VAL DE LOIRE: 2572853\n",
      "CORSE: 338554\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creation et appel de la procédure\n",
    "data = postgres.sql(\"sql/questions/question_3/procedure.sql\",file=True).sql(\"call proc_update_population()\").sql(\"select ncc,population from regions order by ncc limit 5;\").all()\n",
    "\n",
    "for region in data:\n",
    "    print(f'{region[0]}: {region[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Les 2 blocs suivants sont executés dans l'ordre inverse de leur appartition sur l'ennoncé du TP, nous n'avons pas réussi a rendre opérationnel la mise a jour automatiques des populations si les tables régions et départements rejettent toute mise a jour/insertion/suppression.\n",
    "\n",
    "On aurait pu bloquer les tables au niveau des droits et permettre a la procédure de s'executer mais la question portant sur les trigger nous avons fait le blocage par trigger.\n",
    "\n",
    "Ainsi pour tester elles s'executent dans l'ordre inverse à la demande:\n",
    "1. création d'un trigger sur la table de statistiques qui ne se déclenche qu'à la suppression ou si la mise à jour/insertion implique l'indicateur de population\n",
    "2. mise a jour de la tables statistiques pour augmenter une population (cf: cellule suivante)\n",
    "3. création des triggers de blocage d'opération\n",
    "4. test de mise a jour des tables régions et départements afin de constater que l'erreur que nous renvoyons depuis le trigger nous ai bien retournée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant mise à jour:\n",
      "Région: Nouvelle-Aquitaine -> 5979778 habitants\n",
      "Département: Gironde -> 1601845 habitants\n",
      "Ville: Bordeaux -> 257068 habitants\n",
      "\n",
      "Après mise à jour:\n",
      "Région: Nouvelle-Aquitaine -> 5979779 habitants\n",
      "Département: Gironde -> 1601846 habitants\n",
      "Ville: Bordeaux -> 257069 habitants\n"
     ]
    }
   ],
   "source": [
    "# requête interactive\n",
    "\n",
    "ville = 'bordeaux'  # ville ciblée (se base sur le ncc)\n",
    "augmentation = 1 # permet de définir de combien l'on augmente la population de la ville donnée\n",
    "\n",
    "# Mise a jour auto des tables régions et départements quand un indicateur de population est modifié\n",
    "\n",
    "\n",
    "\n",
    "# ne pas modifier en dessous\n",
    "sql = \"\"\"\n",
    "    select r.libelle,r.population, d.libelle,d.population, c.libelle,valeur::integer, c.com\n",
    "    from communes c \n",
    "    join statistiques s on s.codgeo = c.com \n",
    "    join departements d using(dep) \n",
    "    join regions r using(reg) \n",
    "    where c.ncc = upper(%(ville)s) \n",
    "    and s.annee = 2018 \n",
    "    and s.indicateur = 'POP'\n",
    "    group by valeur, r.population, d.population, r.libelle, c.libelle, d.libelle, c.com;\n",
    "\"\"\" # ne pas modifier\n",
    "\n",
    "\n",
    "# dictionnaires utilisés pour constater les différences\n",
    "pre_update = {'region' : None, 'dep': None, 'ville': None} \n",
    "post_update = {'region': None, 'dep': None, 'ville': None}\n",
    "\n",
    "# ajout du trigger\n",
    "pre_update = postgres.sql(\"sql/questions/question_3/triggers_2.sql\",file=True).sql(sql, {'ville': ville}).one()\n",
    "try:\n",
    "    post_update =postgres.sql(\n",
    "        query=\"update statistiques set valeur = %(valeur)s where indicateur = 'POP' and annee = 2018 and codgeo = %(codgeo)s;\", \n",
    "        params={'valeur': pre_update[-2]+augmentation, 'codgeo': str(pre_update[-1])}\n",
    "        ).sql(\n",
    "            query=sql, \n",
    "            params={'ville': ville}\n",
    "            ).one()\n",
    "    print(\"Avant mise à jour:\")\n",
    "    print(f'Région: {pre_update[0]} -> {pre_update[1]} habitants')\n",
    "    print(f'Département: {pre_update[2]} -> {pre_update[3]} habitants')\n",
    "    print(f'Ville: {pre_update[4]} -> {pre_update[5]} habitants')\n",
    "    print(\"\\nAprès mise à jour:\")\n",
    "    print(f'Région: {post_update[0]} -> {post_update[1]} habitants')\n",
    "    print(f'Département: {post_update[2]} -> {post_update[3]} habitants')\n",
    "    print(f'Ville: {post_update[4]} -> {post_update[5]} habitants')\n",
    "except Exception as error:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE on regions is not allowed.\n",
      "CONTEXT:  PL/pgSQL function fun_prevent() line 3 at RAISE\n",
      "\n",
      "UPDATE on departements is not allowed.\n",
      "CONTEXT:  PL/pgSQL function fun_prevent() line 3 at RAISE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Blocage des tables régions et départements\n",
    "\n",
    "postgres.sql(\"sql/questions/question_3/triggers_1.sql\",file=True)\n",
    "try:\n",
    "    postgres.sql(\"update regions set population = 10000 where reg = '75';\")\n",
    "except Exception as error:\n",
    "    print(error)  # UPDATE on regions is not allowed.\n",
    "try:\n",
    "    postgres.connect()\n",
    "    postgres.sql(\"update departements set population = 10000 where dep = '33';\")\n",
    "except Exception as error:\n",
    "    print(error)  # UPDATE on departements is not allowed.\n",
    "\n",
    "postgres.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18)\n",
      "\n",
      "Hash Join  (cost=12.03..38.07 rows=90 width=896)\n",
      "  Hash Cond: ((regions_cheflieu.reg)::text = (regions.reg)::text)\n",
      "  ->  Seq Scan on regions_cheflieu  (cost=0.00..22.70 rows=1270 width=36)\n",
      "  ->  Hash  (cost=10.90..10.90 rows=90 width=856)\n",
      "        ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n"
     ]
    }
   ],
   "source": [
    "# Plans d'executions\n",
    "\n",
    "#1\n",
    "print('#1 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18)\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_small_to_small.sql\",file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361)\n",
      "\n",
      "Hash Join  (cost=13.15..27048.36 rows=885304 width=670)\n",
      "  Hash Cond: ((statistiques.indicateur)::text = (indicateurs.code)::text)\n",
      "  ->  Seq Scan on statistiques  (cost=0.00..24662.04 rows=885304 width=116)\n",
      "  ->  Hash  (cost=11.40..11.40 rows=140 width=554)\n",
      "        ->  Seq Scan on indicateurs  (cost=0.00..11.40 rows=140 width=554)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print('#2 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361)\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_smallest_to_biggest.sql\",file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18) avec tri et ordonnancement\n",
      "\n",
      "Hash Join  (cost=13.15..27048.36 rows=885304 width=670)\n",
      "  Hash Cond: ((statistiques.indicateur)::text = (indicateurs.code)::text)\n",
      "  ->  Seq Scan on statistiques  (cost=0.00..24662.04 rows=885304 width=116)\n",
      "  ->  Hash  (cost=11.40..11.40 rows=140 width=554)\n",
      "        ->  Seq Scan on indicateurs  (cost=0.00..11.40 rows=140 width=554)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#3\n",
    "print('#3 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18) avec tri et ordonnancement\\n')\n",
    "postgres.sql(\"sql/questions/question_6/explain_small_to_small_ordered.sql\",file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361) avec tri et ordonnancement\n",
      "\n",
      "Gather Merge  (cost=24211.10..24211.80 rows=6 width=670)\n",
      "  Workers Planned: 2\n",
      "  ->  Sort  (cost=23211.07..23211.08 rows=3 width=670)\n",
      "        Sort Key: statistiques.valeur\n",
      "        ->  Nested Loop  (cost=0.14..23211.05 rows=3 width=670)\n",
      "              ->  Parallel Seq Scan on statistiques  (cost=0.00..23186.53 rows=3 width=116)\n",
      "                    Filter: (((indicateur)::text = 'POP'::text) AND (annee = 2018) AND ((valeur)::integer > 100000))\n",
      "              ->  Index Scan using indicateurs_pkey on indicateurs  (cost=0.14..8.16 rows=1 width=554)\n",
      "                    Index Cond: ((code)::text = 'POP'::text)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "print('#4 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361) avec tri et ordonnancement\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_smallest_to_biggest_ordered.sql\",file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constats pour les 2eme et 4eme plans d'execution\n",
    "\n",
    "Par rapport a son homologue (#2) on constate une différence de coût pour la requête (#4), le coût final de cette requête est bien plus petit que celui de la requête qui ne faisait que la jointure (46904.81 contre 38601.06) pour un nombre de ligne très largement inferieur dans cette requête (2446515 contre 9076).\n",
    "\n",
    "On peut expliquer la différence de coût par le fait que les 2 requêtes ont été executée a la suite lors du test, la première aura peuplé le cache de la base en aillant déjà fait les calculs nécéssaires sur les index de la jointure entre indicateurs et statisitques. La numéro 4 n'étant qu'une extension de la requête 2 (on a juste ajouté des filtres et tri)\n",
    "\n",
    "On note une grosse différence c'est l'apparition du Workers Planned, qui nous informe qu'en vu d'optimiser le temps de calcul le plannificateur prévois d'utiliser des processus auxiliaires pour executer l'ensemble de la requête (ici 2 processus), s'il intervient ici et n'était pas apparu lors de la #1 c'est certainement a cause du filtre comme on le voit avec le scan parallèle (job auxiliaire) qui applique le filtre.\n",
    "\n",
    "En général la 2eme requête est bien plus optimisée que celle qui fait uniquement la jointure.\n",
    "\n",
    "\n",
    "## Comparaison des duo (2-4) et (1-3)\n",
    "les requêtes #1 et #3 étants effectuées sur de très petites tables (18 entrées) on constate que le plannificateur a tout de même optimisé le temps de calcul pour la #3 qui applique des filtres sur la requête.\n",
    "La où c'est interessants c'est en comparant la #3 et la #4 qui sont similaire (jointure + filtre) le planificateur n'a pas fait appel a des processus auxiliaires contrairement a la #4, probablement a cause de la taille des tables le plannificateur doit estimer que l'utilisation d'un processus auxiliaire ne ferait pas gagner de temps dans ce cas là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965)\n",
      "\n",
      "Hash Join  (cost=25.29..359.42 rows=1162 width=2604)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Seq Scan on communes  (cost=0.00..312.83 rows=2583 width=876)\n",
      "  ->  Hash  (cost=24.16..24.16 rows=90 width=1712)\n",
      "        ->  Hash Join  (cost=12.03..24.16 rows=90 width=1712)\n",
      "              Hash Cond: ((regions.reg)::bpchar = departements.reg)\n",
      "              ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n",
      "              ->  Hash  (cost=10.90..10.90 rows=90 width=868)\n",
      "                    ->  Seq Scan on departements  (cost=0.00..10.90 rows=90 width=868)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "print('#5 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965)\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_triple_join.sql\",file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965) mais la jointure est \"inversée\"\n",
      "\n",
      "Hash Join  (cost=25.29..359.42 rows=1162 width=2604)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Seq Scan on communes  (cost=0.00..312.83 rows=2583 width=876)\n",
      "  ->  Hash  (cost=24.16..24.16 rows=90 width=1708)\n",
      "        ->  Hash Join  (cost=12.03..24.16 rows=90 width=1708)\n",
      "              Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "              ->  Seq Scan on departements  (cost=0.00..10.90 rows=90 width=868)\n",
      "              ->  Hash  (cost=10.90..10.90 rows=90 width=856)\n",
      "                    ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "print('#6 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965) mais la jointure est \"inversée\"\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_triple_join_revert.sql\", file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constat entre la 5 et la 6\n",
    "La 5 part de régions et joint départements puis communes alors que la 6 part de communes et fini sur régions\n",
    "On constate que le plannificateur effectue exactements les mêmes requêtes peut importe l'ordre d'appartition des tables dans le select et ses jointures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M)\n",
      "\n",
      "Hash Join  (cost=373.95..32338.55 rows=398267 width=2720)\n",
      "  Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "  ->  Seq Scan on statistiques  (cost=0.00..24662.04 rows=885304 width=116)\n",
      "  ->  Hash  (cost=359.42..359.42 rows=1162 width=2568)\n",
      "        ->  Hash Join  (cost=25.29..359.42 rows=1162 width=2568)\n",
      "              Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "              ->  Seq Scan on communes  (cost=0.00..312.83 rows=2583 width=876)\n",
      "              ->  Hash  (cost=24.16..24.16 rows=90 width=1708)\n",
      "                    ->  Hash Join  (cost=12.03..24.16 rows=90 width=1708)\n",
      "                          Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "                          ->  Seq Scan on departements  (cost=0.00..10.90 rows=90 width=868)\n",
      "                          ->  Hash  (cost=10.90..10.90 rows=90 width=856)\n",
      "                                ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "print('#7 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M)\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_quad_join.sql\", file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri et ordonancement\n",
      "\n",
      "Hash Join  (cost=373.95..32338.55 rows=398267 width=2720)\n",
      "  Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "  ->  Seq Scan on statistiques  (cost=0.00..24662.04 rows=885304 width=116)\n",
      "  ->  Hash  (cost=359.42..359.42 rows=1162 width=2568)\n",
      "        ->  Hash Join  (cost=25.29..359.42 rows=1162 width=2568)\n",
      "              Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "              ->  Seq Scan on communes  (cost=0.00..312.83 rows=2583 width=876)\n",
      "              ->  Hash  (cost=24.16..24.16 rows=90 width=1708)\n",
      "                    ->  Hash Join  (cost=12.03..24.16 rows=90 width=1708)\n",
      "                          Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "                          ->  Seq Scan on departements  (cost=0.00..10.90 rows=90 width=868)\n",
      "                          ->  Hash  (cost=10.90..10.90 rows=90 width=856)\n",
      "                                ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "print('#8 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri et ordonancement\\n')\n",
    "postgres.sql(\"sql/questions/question_6/explain_quad_join_ordered.sql\", file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constats entre (7-8) et (4-8)\n",
    "## 7-8\n",
    "Comme pour 2-4 on constate que la requête avec des tri est moins coûteuse que la jointure seule également tout ce qui est filtre et ordernancement est géré par des processus auxiliaires (2 également, on peut se demander si ce n'est pas un pour les filtres et un pour le order by, réponse dans la cellule suivante)\n",
    "\n",
    "## 4-8\n",
    "Les 2 requêtes sont similaire (le coût dans la branche des workers est très similaire ~30k) et pourtant la 8 consomme plus que la 4, les jointures impactent sont très certainement à mettre en cause bien que d'autres facteurs entrent en jeux (le fait que toutes soient faites a la suite, la machine etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri\n",
      "\n",
      "Gather  (cost=1344.74..22033.32 rows=2056 width=2720)\n",
      "  Workers Planned: 2\n",
      "  ->  Hash Join  (cost=344.74..20827.72 rows=857 width=2720)\n",
      "        Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "        ->  Hash Join  (cost=319.45..20787.11 rows=1857 width=992)\n",
      "              Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "              ->  Parallel Seq Scan on statistiques  (cost=0.00..19497.77 rows=368877 width=116)\n",
      "              ->  Hash  (cost=319.29..319.29 rows=13 width=876)\n",
      "                    ->  Seq Scan on communes  (cost=0.00..319.29 rows=13 width=876)\n",
      "                          Filter: ((ncc)::text ~~ 'B%'::text)\n",
      "        ->  Hash  (cost=24.16..24.16 rows=90 width=1708)\n",
      "              ->  Hash Join  (cost=12.03..24.16 rows=90 width=1708)\n",
      "                    Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "                    ->  Seq Scan on departements  (cost=0.00..10.90 rows=90 width=868)\n",
      "                    ->  Hash  (cost=10.90..10.90 rows=90 width=856)\n",
      "                          ->  Seq Scan on regions  (cost=0.00..10.90 rows=90 width=856)\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "print('#9 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_quad_join_filtered.sql\", file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constat entre 8 et 9\n",
    "La seule différence entre les 2 est le order by qui a été enlevé dans la 9, on constate que le plannificateur ne fait plus appel aux processus auxiliaires ce qui peut confirmer l'hypothèse émise précedement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#10 - Multiples jointures et fonction d'aggrégat\n",
      "\n",
      "Sort  (cost=10773.82..10773.82 rows=1 width=896)\n",
      "  Sort Key: groupe_region_population.valeur_max DESC\n",
      "  ->  Nested Loop  (cost=9435.56..10773.81 rows=1 width=896)\n",
      "        ->  Nested Loop  (cost=9435.41..10765.63 rows=1 width=930)\n",
      "              Join Filter: (groupe_region_population.valeur_max = s.valeur)\n",
      "              ->  Hash Join  (cost=9434.99..9758.80 rows=129 width=892)\n",
      "                    Hash Cond: (c.dep = (d.dep)::bpchar)\n",
      "                    ->  Seq Scan on communes c  (cost=0.00..312.83 rows=2583 width=458)\n",
      "                    ->  Hash  (cost=9434.86..9434.86 rows=10 width=466)\n",
      "                          ->  Hash Join  (cost=9422.48..9434.86 rows=10 width=466)\n",
      "                                Hash Cond: (d.reg = groupe_region_population.reg)\n",
      "                                ->  Hash Join  (cost=12.03..24.16 rows=90 width=462)\n",
      "                                      Hash Cond: (d.reg = (r.reg)::bpchar)\n",
      "                                      ->  Seq Scan on departements d  (cost=0.00..10.90 rows=90 width=28)\n",
      "                                      ->  Hash  (cost=10.90..10.90 rows=90 width=434)\n",
      "                                            ->  Seq Scan on regions r  (cost=0.00..10.90 rows=90 width=434)\n",
      "                                ->  Hash  (cost=9410.33..9410.33 rows=10 width=44)\n",
      "                                      ->  Subquery Scan on groupe_region_population  (cost=9410.05..9410.33 rows=10 width=44)\n",
      "                                            ->  GroupAggregate  (cost=9410.05..9410.23 rows=10 width=44)\n",
      "                                                  Group Key: d_1.reg\n",
      "                                                  ->  Sort  (cost=9410.05..9410.08 rows=10 width=44)\n",
      "                                                        Sort Key: d_1.reg\n",
      "                                                        ->  Nested Loop  (cost=12.60..9409.89 rows=10 width=44)\n",
      "                                                              ->  Index Only Scan using indicateurs_pkey on indicateurs i_1  (cost=0.14..8.16 rows=1 width=38)\n",
      "                                                                    Index Cond: (code = 'POP'::text)\n",
      "                                                              ->  Nested Loop  (cost=12.45..9401.63 rows=10 width=82)\n",
      "                                                                    ->  Hash Join  (cost=12.03..346.16 rows=1162 width=36)\n",
      "                                                                          Hash Cond: (c1.dep = (d_1.dep)::bpchar)\n",
      "                                                                          ->  Seq Scan on communes c1  (cost=0.00..312.83 rows=2583 width=40)\n",
      "                                                                          ->  Hash  (cost=10.90..10.90 rows=90 width=28)\n",
      "                                                                                ->  Seq Scan on departements d_1  (cost=0.00..10.90 rows=90 width=28)\n",
      "                                                                    ->  Index Scan using statistiques_pkey on statistiques s_1  (cost=0.42..7.79 rows=1 width=94)\n",
      "                                                                          Index Cond: (((codgeo)::text = (c1.com)::text) AND (annee = 2018) AND ((indicateur)::text = 'POP'::text))\n",
      "              ->  Index Scan using statistiques_pkey on statistiques s  (cost=0.42..7.79 rows=1 width=94)\n",
      "                    Index Cond: (((codgeo)::text = (c.com)::text) AND (annee = 2018) AND ((indicateur)::text = 'POP'::text))\n",
      "        ->  Index Only Scan using indicateurs_pkey on indicateurs i  (cost=0.14..8.16 rows=1 width=38)\n",
      "              Index Cond: (code = 'POP'::text)\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "print('#10 - Multiples jointures et fonction d\\'aggrégat\\n')\n",
    "data = postgres.sql(\"sql/questions/question_6/explain_agregate.sql\", file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constat pour la 10\n",
    "Le plan étant conséquent nous nous somme servi d'un outil pour analyser les plans d'execution https://explain.dalibo.com/plan/6T4\n",
    "Dans l'ensemble on constate que le planificateur fait appel a tout ce que l'on a vu précédement, de multiples fois en raison de la sous requête.\n",
    "L'apparition du groupe HashAggregate est nouveau, il intervient a cause de la fonction d'aggrégat utilisée dans la requête. On constate en revanche que malgré la \"complexité\" de cette requête son coup est moins elevé que la n°8 alors qu'elle effectue des jointures similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq Scan on departements  (cost=0.00..11.12 rows=30 width=422)\n",
      "  Filter: (population > 700000)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sort  (cost=11.86..11.94 rows=30 width=422)\n",
      "  Sort Key: population\n",
      "  ->  Seq Scan on departements  (cost=0.00..11.12 rows=30 width=422)\n",
      "        Filter: (population > 700000)\n",
      "\n",
      "#################### CREATION INDEX SUR POPULATION ####################\n",
      "Seq Scan on departements  (cost=0.00..3.26 rows=34 width=422)\n",
      "  Filter: (population > 700000)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sort  (cost=4.13..4.21 rows=34 width=422)\n",
      "  Sort Key: population\n",
      "  ->  Seq Scan on departements  (cost=0.00..3.26 rows=34 width=422)\n",
      "        Filter: (population > 700000)\n"
     ]
    }
   ],
   "source": [
    "# Index departements\n",
    "\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_dep.sql\", file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "print('-' * 100)\n",
    "\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_dep_order.sql\",file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "\n",
    "print('\\n'+'#' * 20 + ' CREATION INDEX SUR POPULATION ' + '#'*20)\n",
    "data = postgres.sql(\"sql/questions/question_7/create_population_index.sql\",file=True).sql(\"sql/questions/question_7/explain_dep.sql\",file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "print('-' * 100)\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_dep_order.sql\",file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sans index avec filtre sans order by:\n",
      "Gather  (cost=1000.00..22489.75 rows=1476 width=58)\n",
      "  Workers Planned: 2\n",
      "  ->  Parallel Seq Scan on statistiques  (cost=0.00..21342.15 rows=615 width=58)\n",
      "        Filter: ((valeur > 10000.0) AND ((indicateur)::text = 'POP'::text))\n",
      "Sans index avec filtre et order by----------------------------------------------------------------------------------------------------\n",
      "Gather Merge  (cost=22370.66..22514.17 rows=1230 width=58)\n",
      "  Workers Planned: 2\n",
      "  ->  Sort  (cost=21370.64..21372.18 rows=615 width=58)\n",
      "        Sort Key: annee\n",
      "        ->  Parallel Seq Scan on statistiques  (cost=0.00..21342.15 rows=615 width=58)\n",
      "              Filter: ((valeur > 10000.0) AND ((indicateur)::text = 'POP'::text))\n",
      "\n",
      "#################### CREATION INDEX SUR valeur ####################\n",
      "Avec index avec filtre sans order by\n",
      "Gather  (cost=1000.00..32506.45 rows=4077 width=58)\n",
      "  Workers Planned: 2\n",
      "  ->  Parallel Seq Scan on statistiques  (cost=0.00..31098.75 rows=1699 width=58)\n",
      "        Filter: ((valeur > 10000.0) AND ((indicateur)::text = 'POP'::text))\n",
      "Avec index avec filtre et order by----------------------------------------------------------------------------------------------------\n",
      "Gather Merge  (cost=32189.93..32586.39 rows=3398 width=58)\n",
      "  Workers Planned: 2\n",
      "  ->  Sort  (cost=31189.91..31194.15 rows=1699 width=58)\n",
      "        Sort Key: annee\n",
      "        ->  Parallel Seq Scan on statistiques  (cost=0.00..31098.75 rows=1699 width=58)\n",
      "              Filter: ((valeur > 10000.0) AND ((indicateur)::text = 'POP'::text))\n"
     ]
    }
   ],
   "source": [
    "# Test d'index sur la table statistiques\n",
    "\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_stats.sql\",file=True).all()\n",
    "\n",
    "print('Sans index avec filtre sans order by:')\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "print('Sans index avec filtre et order by' + ('-' * 100))\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_stats_order.sql\",file=True).all()\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "\n",
    "print('\\n'+'#' * 20 + ' CREATION INDEX SUR valeur ' + '#'*20)\n",
    "data = postgres.sql(\"sql/questions/question_7/create_valeur_index.sql\",file=True).sql(\"sql/questions/question_7/explain_stats.sql\",file=True).all()\n",
    "\n",
    "print('Avec index avec filtre sans order by')\n",
    "for state in data:\n",
    "    print(state[0])\n",
    "print('Avec index avec filtre et order by' + ('-' * 100))\n",
    "\n",
    "data = postgres.sql(\"sql/questions/question_7/explain_stats_order.sql\",file=True).all()\n",
    "\n",
    "for state in data:\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constats pour les index\n",
    "On constate que sur la table départements, la présence ou non d'un index ne change absolument pas la façon dont le planificateur prépare sa requête probablement a cause de la taille de la table qui est vraiment petite  \n",
    "\n",
    "En revanche pour la table de statistiques, on constate que le planificateur change d'algorithme et utilise un scan différent (Bitmap heap scan) et qu'en plus de cela il n'a plus recours a des processus auxiliaires (la consommation de resources est très probablement diminuée également de ce fait) et cela a pour impact une reduction drastiques des coûts:\n",
    "- Entre les requêtes avec filtres et sans order by:\n",
    "  - diminution du coût estimé par ~2.5 \n",
    "    - cost=1000.00..32355.95 sans l'index\n",
    "    - cost=433.27..17392.90 avec index\n",
    "<hr>\n",
    "\n",
    "- Entre les requêtes avec filtres et order by:\n",
    "  - diminution du coût estimé par ~1.8 \n",
    "    - cost=32152.73..32402.88 sans l'index\n",
    "    - cost=17538.59..17545.02 avec index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres.close(True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
