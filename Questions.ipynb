{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2 as postgres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'tp_dba'\n",
    "USER = 'axelmoriceau'\n",
    "PSWD = ''\n",
    "\n",
    "def connect():\n",
    "    conn = postgres.connect(\n",
    "        host='localhost',\n",
    "        database=BASE,\n",
    "        user=USER,\n",
    "        password=PSWD,\n",
    "        port='5432'\n",
    "    )\n",
    "    return conn\n",
    "conn = connect()\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(open(\"sql/questions/reset.sql\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les départements qui correspondent a la région aquitaine:\n",
      "\t- Charente\n",
      "\t- Charente-Maritime\n",
      "\t- Corrèze\n",
      "\t- Creuse\n",
      "\t- Deux-Sèvres\n",
      "\t- Dordogne\n",
      "\t- Gironde\n",
      "\t- Haute-Vienne\n",
      "\t- Landes\n",
      "\t- Lot-et-Garonne\n",
      "\t- Pyrénées-Atlantiques\n",
      "\t- Vienne\n"
     ]
    }
   ],
   "source": [
    "# requête interactive\n",
    "region = 'aquitaine' # mettre a jour le contenu ici pour changer de région (i.e: tagne -> Bretagne, compte -> Franche compté etc)\n",
    "\n",
    "cur.execute(\"select d.libelle from departements d join regions r using(reg) where r.ncc LIKE UPPER(%(region)s) or r.libelle LIKE UPPER(%(region)s) order by d.libelle\", {'region': f'%{region}%'})\n",
    "conn.commit()\n",
    "data = cur.fetchall()\n",
    "\n",
    "print(f'Les départements qui correspondent a la région {region}:')\n",
    "for dep in data:\n",
    "    print(f'\\t- {dep[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information pour l'indicateur pop pour la commune bordeaux (33 )\n",
      "\t1968: 257,070\n",
      "\t1975: 257,070\n",
      "\t1982: 257,070\n",
      "\t1990: 257,070\n",
      "\t1999: 257,070\n",
      "\t2008: 257,070\n",
      "\t2013: 257,070\n",
      "\t2018: 257,871\n"
     ]
    }
   ],
   "source": [
    "commune = 'bordeaux'  # le nom de la ville doit être exact, sans accent ni caractère spéciaux\n",
    "indicateur = 'pop'  # parmis DECE, LOG, LOGVAC, NAIS, NPER, PMEN, POP, RP, RSECOCC, SUPERF\n",
    "\n",
    "cur.execute(\"select annee, ncc, dep,valeur from communes c join statistiques s on s.codgeo = c.com where upper(s.indicateur) = upper(%(indicateur)s) and c.ncc = upper( %(commune)s)\", \n",
    "            {'commune': commune, 'indicateur': indicateur})\n",
    "conn.commit()\n",
    "data = cur.fetchall()\n",
    "\n",
    "if(len(data)):\n",
    "    print(f\"Information pour l'indicateur {indicateur} pour la commune {commune} ({data[0][2]})\")\n",
    "    for info in data:\n",
    "        print(f'\\t{info[0]}: {info[3]:,}')\n",
    "else:\n",
    "    print(f'aucune information pour la commune de {commune} et l\\'indicateur {indicateur}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 villes les plus peuplées de France en 2018:\n",
      "\t- Paris: 2,175,702 habitants\n",
      "\t- Marseille: 868,277 habitants\n",
      "\t- Lyon: 518,635 habitants\n",
      "\t- Toulouse: 486,828 habitants\n",
      "\t- Nice: 341,032 habitants\n",
      "\t- Montpellier: 290,053 habitants\n",
      "\t- Strasbourg: 284,677 habitants\n",
      "\t- Bordeaux: 257,871 habitants\n",
      "\t- Lille: 233,098 habitants\n",
      "\t- Rennes: 217,728 habitants\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "cur.execute(open(\"sql/questions/question_1/question_1#1.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "data = cur.fetchall()\n",
    "\n",
    "print('Les 10 villes les plus peuplées de France en 2018:')\n",
    "for ville in data:\n",
    "    print(f'\\t- {ville[0]}: {ville[1]:,} habitants')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évolution de la population Française au fil des années:\n",
      "\n",
      "\t- Année 1968: 50,788,520 habitants -> +0 habitants (0%)\n",
      "\t\t- Naissances: 6,378,063 | Décès: 4,144,525\n",
      "\n",
      "\t- Année 1975: 53,798,003 habitants -> +3,009,483 habitants (5.5940422175150255%)\n",
      "\t\t- Naissances: 5,767,687 | Décès: 4,149,276\n",
      "\t\t- Augmentation: 3,009,483 || Naissances - Décès: 1,618,411 || Différence: 1,391,072\n",
      "\n",
      "\t- Année 1982: 55,618,453 habitants -> +1,820,450 habitants (3.273104341826983%)\n",
      "\t\t- Naissances: 6,599,046 | Décès: 4,613,309\n",
      "\t\t- Augmentation: 1,820,450 || Naissances - Décès: 1,985,737 || Différence: -165,287\n",
      "\n",
      "\t- Année 1990: 58,087,393 habitants -> +2,468,940 habitants (4.250388720320087%)\n",
      "\t\t- Naissances: 7,110,433 | Décès: 5,057,784\n",
      "\t\t- Augmentation: 2,468,940 || Naissances - Décès: 2,052,649 || Différence: 416,291\n",
      "\n",
      "\t- Année 1999: 60,191,608 habitants -> +2,104,215 habitants (3.495861084156449%)\n",
      "\t\t- Naissances: 7,442,930 | Décès: 5,074,193\n",
      "\t\t- Augmentation: 2,104,215 || Naissances - Décès: 2,368,737 || Différence: -264,522\n",
      "\n",
      "\t- Année 2008: 63,983,038 habitants -> +3,791,430 habitants (5.925679865341811%)\n",
      "\t\t- Naissances: 4,364,197 | Décès: 2,996,393\n",
      "\t\t- Augmentation: 3,791,430 || Naissances - Décès: 1,367,804 || Différence: 2,423,626\n",
      "\n",
      "\t- Année 2013: 65,578,200 habitants -> +1,595,162 habitants (2.432457737479833%)\n",
      "\t\t- Naissances: 4,178,457 | Décès: 3,157,310\n",
      "\t\t- Augmentation: 1,595,162 || Naissances - Décès: 1,021,147 || Différence: 574,015\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "cur.execute(open(\"sql/questions/question_1/question_1#2.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "data = cur.fetchall()\n",
    "\n",
    "print('Évolution de la population Française au fil des années:')\n",
    "for population in data:\n",
    "    population = [0 if v is None else v for v in population]\n",
    "    print(f'\\n\\t- Année {population[0]}: {population[1]:,} habitants -> +{population[2]:,} habitants ({population[3]}%)')\n",
    "    print(f'\\t\\t- Naissances: {population[4]:,} | Décès: {population[5]:,}')\n",
    "    if(population[2]):\n",
    "        print(f'\\t\\t- Augmentation: {population[2]:,} || Naissances - Décès: {population[4] - population[5]:,} || Différence: {population[2]-(population[4] - population[5]):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ville la plus peuplée de chaque région en 2018:\n",
      "\t- Région Île-de-France -> Paris (75056): 2,175,702 habitants\n",
      "\t- Région Provence-Alpes-Côte d'Azur -> Marseille (13055): 868,277 habitants\n",
      "\t- Région Auvergne-Rhône-Alpes -> Lyon (69123): 518,635 habitants\n",
      "\t- Région Occitanie -> Toulouse (31555): 486,828 habitants\n",
      "\t- Région Grand Est -> Strasbourg (67482): 284,677 habitants\n",
      "\t- Région Nouvelle-Aquitaine -> Bordeaux (33063): 257,871 habitants\n",
      "\t- Région Hauts-de-France -> Lille (59350): 233,098 habitants\n",
      "\t- Région Bretagne -> Rennes (35238): 217,728 habitants\n",
      "\t- Région Normandie -> Le Havre (76351): 169,733 habitants\n",
      "\t- Région Bourgogne-Franche-Comté -> Dijon (21231): 156,854 habitants\n",
      "\t- Région Pays de la Loire -> Angers (49007): 154,508 habitants\n",
      "\t- Région La Réunion -> Saint-Denis (97411): 150,535 habitants\n",
      "\t- Région Centre-Val de Loire -> Tours (37261): 136,463 habitants\n",
      "\t- Région Martinique -> Fort-de-France (97209): 78,126 habitants\n",
      "\t- Région Corse -> Ajaccio (2A004): 70,817 habitants\n",
      "\t- Région Guyane -> Cayenne (97302): 63,652 habitants\n",
      "\t- Région Guadeloupe -> Les Abymes (97101): 53,082 habitants\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "cur.execute(open(\"sql/questions/question_1/question_1#3.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "data = cur.fetchall()\n",
    "\n",
    "print('Ville la plus peuplée de chaque région en 2018:')\n",
    "for population in data:\n",
    "    print(f'\\t- Région {population[2]} -> {population[1]} ({population[0]}): {population[3]:,} habitants')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des vues\n",
    "\n",
    "cur.execute(open(\"sql/questions/question_2/question_2#vue_region.sql\", \"r\").read())\n",
    "cur.execute(open(\"sql/questions/question_2/question_2#vue_departements.sql\", \"r\").read())\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUVERGNE RHONE ALPES: None\n",
      "BOURGOGNE FRANCHE COMTE: None\n",
      "BRETAGNE: None\n",
      "CENTRE VAL DE LOIRE: None\n",
      "CORSE: None\n"
     ]
    }
   ],
   "source": [
    "# Ajout des colonnes population\n",
    "cur.execute(open(\"sql/questions/question_3/alter_tables.sql\", \"r\").read())\n",
    "cur.execute(\"select ncc,population from regions order by ncc limit 5;\")\n",
    "conn.commit()\n",
    "\n",
    "data = cur.fetchall()\n",
    "for region in data:\n",
    "    print(f'{region[0]}: {region[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUVERGNE RHONE ALPES: 7994459\n",
      "BOURGOGNE FRANCHE COMTE: 2807807\n",
      "BRETAGNE: 3335226\n",
      "CENTRE VAL DE LOIRE: 2572853\n",
      "CORSE: 338554\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creation et appel de la procédure\n",
    "cur.execute(open(\"sql/questions/question_3/procedure.sql\", \"r\").read())\n",
    "cur.execute(\"call proc_update_population()\")\n",
    "cur.execute(\"select ncc,population from regions order by ncc limit 5;\")\n",
    "conn.commit()\n",
    "\n",
    "data = cur.fetchall()\n",
    "for region in data:\n",
    "    print(f'{region[0]}: {region[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Les 2 blocs suivants sont executés dans l'ordre inverse de leur appartition sur l'ennoncé du TP, nous n'avons pas réussi a rendre opérationnel la mise a jour automatiques des populations si les tables régions et départements rejettent toute mise a jour/insertion/suppression.\n",
    "\n",
    "On aurait pu bloquer les tables au niveau des droits et permettre a la procédure de s'executer mais la question portant sur les trigger nous avons fait le blocage par trigger.\n",
    "\n",
    "Ainsi pour tester elles s'executent dans l'ordre inverse à la demande:\n",
    "1. création d'un trigger sur la table de statistiques qui ne se déclenche qu'à la suppression ou si la mise à jour/insertion implique l'indicateur de population\n",
    "2. mise a jour de la tables statistiques pour augmenter une population (cf: cellule suivante)\n",
    "3. création des triggers de blocage d'opération\n",
    "4. test de mise a jour des tables régions et départements afin de constater que l'erreur que nous renvoyons depuis le trigger nous ai bien retournée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant mise à jour:\n",
      "Région: Nouvelle-Aquitaine -> 5980581 habitants\n",
      "Département: Gironde -> 1602648 habitants\n",
      "Ville: Bordeaux -> 257871 habitants\n",
      "\n",
      "Après mise à jour:\n",
      "Région: Nouvelle-Aquitaine -> 5980582 habitants\n",
      "Département: Gironde -> 1602649 habitants\n",
      "Ville: Bordeaux -> 257872 habitants\n"
     ]
    }
   ],
   "source": [
    "# Mise a jour auto des tables régions et départements quand un indicateur de population est modifié\n",
    "\n",
    "ville = 'bordeaux'  # ville ciblée (se base sur le ncc)\n",
    "augmentation = 1 # permet de définir de combien l'on augmente la population de la ville donnée\n",
    "\n",
    "# ne pas modifier en dessous\n",
    "sql = \"\"\"\n",
    "    select r.libelle,r.population, d.libelle,d.population, c.libelle,valeur::integer, c.com\n",
    "    from communes c \n",
    "    join statistiques s on s.codgeo = c.com \n",
    "    join departements d using(dep) \n",
    "    join regions r using(reg) \n",
    "    where c.ncc = upper(%(ville)s) \n",
    "    and s.annee = 2018 \n",
    "    and s.indicateur = 'POP'\n",
    "    group by valeur, r.population, d.population, r.libelle, c.libelle, d.libelle, c.com;\n",
    "\"\"\" # ne pas modifier\n",
    "\n",
    "\n",
    "# dictionnaires utilisés pour constater les différences\n",
    "pre_update = {'region' : None, 'dep': None, 'ville': None} \n",
    "post_update = {'region': None, 'dep': None, 'ville': None}\n",
    "\n",
    "# ajout du trigger\n",
    "cur.execute(open(\"sql/questions/question_3/triggers_2.sql\", \"r\").read())\n",
    "cur.execute(sql, {'ville': ville})\n",
    "conn.commit()\n",
    "pre_update = list(cur.fetchone())\n",
    "try:\n",
    "    cur.execute(\"update statistiques set valeur = %(valeur)s where indicateur = 'POP' and annee = 2018 and codgeo = %(codgeo)s;\", {'valeur': pre_update[-2]+augmentation, 'codgeo': str(pre_update[-1])})\n",
    "    cur.execute(sql, {'ville': ville})\n",
    "    conn.commit()\n",
    "    post_update = list(cur.fetchone())\n",
    "    print(\"Avant mise à jour:\")\n",
    "    print(f'Région: {pre_update[0]} -> {pre_update[1]} habitants')\n",
    "    print(f'Département: {pre_update[2]} -> {pre_update[3]} habitants')\n",
    "    print(f'Ville: {pre_update[4]} -> {pre_update[5]} habitants')\n",
    "    print(\"\\nAprès mise à jour:\")\n",
    "    print(f'Région: {post_update[0]} -> {post_update[1]} habitants')\n",
    "    print(f'Département: {post_update[2]} -> {post_update[3]} habitants')\n",
    "    print(f'Ville: {post_update[4]} -> {post_update[5]} habitants')\n",
    "except Exception as error:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE on regions is not allowed.\n",
      "CONTEXT:  PL/pgSQL function fun_prevent() line 3 at RAISE\n",
      "\n",
      "UPDATE on departements is not allowed.\n",
      "CONTEXT:  PL/pgSQL function fun_prevent() line 3 at RAISE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Blocage des tables régions et départements\n",
    "\n",
    "cur.execute(open(\"sql/questions/question_3/triggers_1.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "try:\n",
    "    cur.execute(\"update regions set population = 10000 where reg = '75';\")\n",
    "except Exception as error:\n",
    "    print(error)  # UPDATE on regions is not allowed.\n",
    "try:\n",
    "    conn = connect()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"update departements set population = 10000 where dep = '33';\")\n",
    "except Exception as error:\n",
    "    print(error)  # UPDATE on departements is not allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18)\n",
      "\n",
      "Hash Join  (cost=2.41..28.45 rows=18 width=87)\n",
      "  Hash Cond: ((regions_cheflieu.reg)::text = (regions.reg)::text)\n",
      "  ->  Seq Scan on regions_cheflieu  (cost=0.00..22.70 rows=1270 width=36)\n",
      "  ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "        ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "# Plans d'executions\n",
    "\n",
    "#1\n",
    "print('#1 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18)\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_small_to_small.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361)\n",
      "\n",
      "Hash Join  (cost=13.15..46904.81 rows=2446515 width=574)\n",
      "  Hash Cond: ((statistiques.indicateur)::text = (indicateurs.code)::text)\n",
      "  ->  Seq Scan on statistiques  (cost=0.00..40275.15 rows=2446515 width=20)\n",
      "  ->  Hash  (cost=11.40..11.40 rows=140 width=554)\n",
      "        ->  Seq Scan on indicateurs  (cost=0.00..11.40 rows=140 width=554)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print('#2 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361)\\n')\n",
    "cur.execute(\n",
    "    open(\"sql/questions/question_4/explain_smallest_to_biggest.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18) avec tri et ordonnancement\n",
      "\n",
      "Sort  (cost=10.42..10.42 rows=1 width=87)\n",
      "  Sort Key: ((regions.reg)::character varying)\n",
      "  ->  Nested Loop  (cost=0.15..10.41 rows=1 width=87)\n",
      "        ->  Seq Scan on regions  (cost=0.00..2.23 rows=1 width=33)\n",
      "              Filter: ((ncc)::text ~~ '%BRETA%'::text)\n",
      "        ->  Index Scan using regions_cheflieu_pkey on regions_cheflieu  (cost=0.15..8.17 rows=1 width=36)\n",
      "              Index Cond: ((reg)::text = (regions.reg)::text)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#3\n",
    "print('#3 - Jointure entre les 2 plus petites tables regions et regions_cheflieu card(18:18) avec tri et ordonnancement\\n')\n",
    "cur.execute(\n",
    "    open(\"sql/questions/question_4/explain_small_to_small_ordered.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361) avec tri et ordonnancement\n",
      "\n",
      "Nested Loop  (cost=37422.54..38601.06 rows=9076 width=574)\n",
      "  ->  Gather Merge  (cost=37422.39..38479.44 rows=9076 width=20)\n",
      "        Workers Planned: 2\n",
      "        ->  Sort  (cost=36422.37..36431.82 rows=3782 width=20)\n",
      "              Sort Key: statistiques.valeur\n",
      "              ->  Parallel Seq Scan on statistiques  (cost=0.00..36197.62 rows=3782 width=20)\n",
      "                    Filter: (((indicateur)::text = 'POP'::text) AND (annee = 2018) AND ((valeur)::integer > 100000))\n",
      "  ->  Materialize  (cost=0.14..8.17 rows=1 width=554)\n",
      "        ->  Index Scan using indicateurs_pkey on indicateurs  (cost=0.14..8.16 rows=1 width=554)\n",
      "              Index Cond: ((code)::text = 'POP'::text)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "print('#4 - Jointure entre la plus petite table (indicateurs) et la plus grande (statistiques) card(10:2446361) avec tri et ordonnancement\\n')\n",
    "cur.execute(open(\n",
    "    \"sql/questions/question_4/explain_smallest_to_biggest_ordered.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constats pour les 2eme et 4eme plans d'execution\n",
    "\n",
    "Par rapport a son homologue (#2) on constate une différence de coût pour la requête (#4), le coût final de cette requête est bien plus petit que celui de la requête qui ne faisait que la jointure (46904.81 contre 38601.06) pour un nombre de ligne très largement inferieur dans cette requête (2446515 contre 9076).\n",
    "\n",
    "On peut expliquer la différence de coût par le fait que les 2 requêtes ont été executée a la suite lors du test, la première aura peuplé le cache de la base en aillant déjà fait les calculs nécéssaires sur les index de la jointure entre indicateurs et statisitques. La numéro 4 n'étant qu'une extension de la requête 2 (on a juste ajouté des filtres et tri)\n",
    "\n",
    "On note une grosse différence c'est l'apparition du Workers Planned, qui nous informe qu'en vu d'optimiser le temps de calcul le plannificateur prévois d'utiliser des processus auxiliaires pour executer l'ensemble de la requête (ici 2 processus), s'il intervient ici et n'était pas apparu lors de la #1 c'est certainement a cause du filtre comme on le voit avec le scan parallèle (job auxiliaire) qui applique le filtre.\n",
    "\n",
    "En général la 2eme requête est bien plus optimisée que celle qui fait uniquement la jointure.\n",
    "\n",
    "\n",
    "## Comparaison des duo (2-4) et (1-3)\n",
    "les requêtes #1 et #3 étants effectuées sur de très petites tables (18 entrées) on constate que le plannificateur a tout de même optimisé le temps de calcul pour la #3 qui applique des filtres sur la requête.\n",
    "La où c'est interessants c'est en comparant la #3 et la #4 qui sont similaire (jointure + filtre) le planificateur n'a pas fait appel a des processus auxiliaires contrairement a la #4, probablement a cause de la taille des tables le plannificateur doit estimer que l'utilisation d'un processus auxiliaire ne ferait pas gagner de temps dans ce cas là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965)\n",
      "\n",
      "Hash Join  (cost=20.07..1137.49 rows=34965 width=150)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Seq Scan on communes  (cost=0.00..636.65 rows=34965 width=35)\n",
      "  ->  Hash  (cost=18.80..18.80 rows=101 width=60)\n",
      "        ->  Hash Join  (cost=2.41..18.80 rows=101 width=60)\n",
      "              Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "              ->  Seq Scan on departements  (cost=0.00..15.01 rows=101 width=30)\n",
      "              ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "                    ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "print('#5 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965)\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_triple_join.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965) mais la jointure est \"inversée\"\n",
      "\n",
      "Hash Join  (cost=20.07..1137.49 rows=34965 width=150)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Seq Scan on communes  (cost=0.00..636.65 rows=34965 width=35)\n",
      "  ->  Hash  (cost=18.80..18.80 rows=101 width=61)\n",
      "        ->  Hash Join  (cost=2.41..18.80 rows=101 width=61)\n",
      "              Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "              ->  Seq Scan on departements  (cost=0.00..15.01 rows=101 width=30)\n",
      "              ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "                    ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "print('#6 - Multiples jointures entre les tables regions, departements et communes card(18:101:34965) mais la jointure est \"inversée\"\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_triple_join_revert.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constat entre la 5 et la 6\n",
    "La 5 part de régions et joint départements puis communes alors que la 6 part de communes et fini sur régions\n",
    "On constate que le plannificateur effectue exactements les mêmes requêtes peut importe l'ordre d'appartition des tables dans le select et ses jointures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M)\n",
      "\n",
      "Hash Join  (cost=1093.78..81431.39 rows=2446515 width=170)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Hash Join  (cost=1073.71..47771.74 rows=2446515 width=55)\n",
      "        Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "        ->  Seq Scan on statistiques  (cost=0.00..40275.15 rows=2446515 width=20)\n",
      "        ->  Hash  (cost=636.65..636.65 rows=34965 width=35)\n",
      "              ->  Seq Scan on communes  (cost=0.00..636.65 rows=34965 width=35)\n",
      "  ->  Hash  (cost=18.80..18.80 rows=101 width=61)\n",
      "        ->  Hash Join  (cost=2.41..18.80 rows=101 width=61)\n",
      "              Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "              ->  Seq Scan on departements  (cost=0.00..15.01 rows=101 width=30)\n",
      "              ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "                    ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "print('#7 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M)\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_quad_join.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri et ordonancement\n",
      "\n",
      "Gather Merge  (cost=49496.46..73817.79 rows=208454 width=170)\n",
      "  Workers Planned: 2\n",
      "  ->  Sort  (cost=48496.44..48757.01 rows=104227 width=170)\n",
      "        Sort Key: statistiques.annee\n",
      "        ->  Hash Join  (cost=788.82..30901.95 rows=104227 width=170)\n",
      "              Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "              ->  Hash Join  (cost=768.75..29448.76 rows=104227 width=55)\n",
      "                    Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "                    ->  Parallel Seq Scan on statistiques  (cost=0.00..26003.81 rows=1019381 width=20)\n",
      "                    ->  Hash  (cost=724.06..724.06 rows=3575 width=35)\n",
      "                          ->  Seq Scan on communes  (cost=0.00..724.06 rows=3575 width=35)\n",
      "                                Filter: ((ncc)::text ~~ 'B%'::text)\n",
      "              ->  Hash  (cost=18.80..18.80 rows=101 width=61)\n",
      "                    ->  Hash Join  (cost=2.41..18.80 rows=101 width=61)\n",
      "                          Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "                          ->  Seq Scan on departements  (cost=0.00..15.01 rows=101 width=30)\n",
      "                          ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "                                ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "print('#8 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri et ordonancement\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_quad_join_ordered.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constats entre (7-8) et (4-8)\n",
    "## 7-8\n",
    "Comme pour 2-4 on constate que la requête avec des tri est moins coûteuse que la jointure seule également tout ce qui est filtre et ordernancement est géré par des processus auxiliaires (2 également, on peut se demander si ce n'est pas un pour les filtres et un pour le order by, réponse dans la cellule suivante)\n",
    "\n",
    "## 4-8\n",
    "Les 2 requêtes sont similaire (le coût dans la branche des workers est très similaire ~30k) et pourtant la 8 consomme plus que la 4, les jointures impactent sont très certainement à mettre en cause bien que d'autres facteurs entrent en jeux (le fait que toutes soient faites a la suite, la machine etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri\n",
      "\n",
      "Hash Join  (cost=788.82..50926.33 rows=250144 width=170)\n",
      "  Hash Cond: (communes.dep = (departements.dep)::bpchar)\n",
      "  ->  Hash Join  (cost=768.75..47466.78 rows=250144 width=55)\n",
      "        Hash Cond: ((statistiques.codgeo)::text = (communes.com)::text)\n",
      "        ->  Seq Scan on statistiques  (cost=0.00..40275.15 rows=2446515 width=20)\n",
      "        ->  Hash  (cost=724.06..724.06 rows=3575 width=35)\n",
      "              ->  Seq Scan on communes  (cost=0.00..724.06 rows=3575 width=35)\n",
      "                    Filter: ((ncc)::text ~~ 'B%'::text)\n",
      "  ->  Hash  (cost=18.80..18.80 rows=101 width=61)\n",
      "        ->  Hash Join  (cost=2.41..18.80 rows=101 width=61)\n",
      "              Hash Cond: (departements.reg = (regions.reg)::bpchar)\n",
      "              ->  Seq Scan on departements  (cost=0.00..15.01 rows=101 width=30)\n",
      "              ->  Hash  (cost=2.18..2.18 rows=18 width=33)\n",
      "                    ->  Seq Scan on regions  (cost=0.00..2.18 rows=18 width=33)\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "print('#9 - Multiples jointures entre les tables regions, departements, communes et statistiques card(18:101:34965:~2M) avec tri\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_quad_join_filtered.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constat entre 8 et 9\n",
    "La seule différence entre les 2 est le order by qui a été enlevé dans la 9, on constate que le plannificateur ne fait plus appel aux processus auxiliaires ce qui peut confirmer l'hypothèse émise précedement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#10 - Multiples jointures et fonction d'aggrégat\n",
      "\n",
      "Sort  (cost=71486.20..71486.20 rows=2 width=69)\n",
      "  Sort Key: groupe_region_population.valeur_max DESC\n",
      "  ->  Nested Loop  (cost=37535.70..71486.19 rows=2 width=69)\n",
      "        ->  Index Only Scan using indicateurs_pkey on indicateurs i  (cost=0.14..8.16 rows=1 width=38)\n",
      "              Index Cond: (code = 'POP'::text)\n",
      "        ->  Hash Join  (cost=37535.55..71478.00 rows=2 width=70)\n",
      "              Hash Cond: (d.reg = (r.reg)::bpchar)\n",
      "              ->  Hash Join  (cost=37533.15..71475.57 rows=2 width=62)\n",
      "                    Hash Cond: ((c.dep = (d.dep)::bpchar) AND (groupe_region_population.reg = d.reg))\n",
      "                    ->  Nested Loop  (cost=37516.62..71458.68 rows=45 width=63)\n",
      "                          ->  Hash Join  (cost=37516.33..71442.30 rows=45 width=46)\n",
      "                                Hash Cond: (s.valeur = groupe_region_population.valeur_max)\n",
      "                                ->  Gather  (cost=1000.00..34823.42 rows=27227 width=17)\n",
      "                                      Workers Planned: 2\n",
      "                                      ->  Parallel Seq Scan on statistiques s  (cost=0.00..31100.72 rows=11345 width=17)\n",
      "                                            Filter: (((indicateur)::text = 'POP'::text) AND (annee = 2018))\n",
      "                                ->  Hash  (cost=36516.11..36516.11 rows=18 width=35)\n",
      "                                      ->  Subquery Scan on groupe_region_population  (cost=36515.75..36516.11 rows=18 width=35)\n",
      "                                            ->  HashAggregate  (cost=36515.75..36515.93 rows=18 width=35)\n",
      "                                                  Group Key: d_1.reg\n",
      "                                                  ->  Nested Loop  (cost=2090.13..36379.61 rows=27227 width=9)\n",
      "                                                        ->  Index Only Scan using indicateurs_pkey on indicateurs i_1  (cost=0.14..8.16 rows=1 width=38)\n",
      "                                                              Index Cond: (code = 'POP'::text)\n",
      "                                                        ->  Gather  (cost=2089.99..36099.18 rows=27227 width=14)\n",
      "                                                              Workers Planned: 2\n",
      "                                                              ->  Hash Join  (cost=1089.99..32376.48 rows=11345 width=14)\n",
      "                                                                    Hash Cond: (c1.dep = (d_1.dep)::bpchar)\n",
      "                                                                    ->  Hash Join  (cost=1073.71..32204.21 rows=11345 width=15)\n",
      "                                                                          Hash Cond: ((s_1.codgeo)::text = (c1.com)::text)\n",
      "                                                                          ->  Parallel Seq Scan on statistiques s_1  (cost=0.00..31100.72 rows=11345 width=17)\n",
      "                                                                                Filter: (((indicateur)::text = 'POP'::text) AND (annee = 2018))\n",
      "                                                                          ->  Hash  (cost=636.65..636.65 rows=34965 width=10)\n",
      "                                                                                ->  Seq Scan on communes c1  (cost=0.00..636.65 rows=34965 width=10)\n",
      "                                                                    ->  Hash  (cost=15.01..15.01 rows=101 width=6)\n",
      "                                                                          ->  Seq Scan on departements d_1  (cost=0.00..15.01 rows=101 width=6)\n",
      "                          ->  Index Scan using communes_pkey on communes c  (cost=0.29..0.36 rows=1 width=23)\n",
      "                                Index Cond: ((com)::text = (s.codgeo)::text)\n",
      "                    ->  Hash  (cost=15.01..15.01 rows=101 width=6)\n",
      "                          ->  Seq Scan on departements d  (cost=0.00..15.01 rows=101 width=6)\n",
      "              ->  Hash  (cost=2.18..2.18 rows=18 width=16)\n",
      "                    ->  Seq Scan on regions r  (cost=0.00..2.18 rows=18 width=16)\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "print('#10 - Multiples jointures et fonction d\\'aggrégat\\n')\n",
    "cur.execute(open(\"sql/questions/question_4/explain_agregate.sql\", \"r\").read())\n",
    "conn.commit()\n",
    "for state in cur.fetchall():\n",
    "    print(state[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constat pour la 10\n",
    "Le plan étant conséquent nous nous somme servi d'un outil pour analyser les plans d'execution https://explain.dalibo.com/plan/6T4\n",
    "Dans l'ensemble on constate que le planificateur fait appel a tout ce que l'on a vu précédement, de multiples fois en raison de la sous requête.\n",
    "L'apparition du groupe HashAggregate est nouveau, il intervient a cause de la fonction d'aggrégat utilisée dans la requête. On constate en revanche que malgré la \"complexité\" de cette requête son coup est moins elevé que la n°8 alors qu'elle effectue des jointures similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
